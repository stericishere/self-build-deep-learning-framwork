import matplotlib.pyplot as plt
import numpy as np
import Array

# helper function
def l2_distance(A: Array, B: Array) -> Array:
    """
    Input: A is a Nxd matrix
           B is a Mxd matirx
    Output: dist is a NxM matrix where dist[i,j] is the 2-norm between A[i,:] and B[j,:]
    i.e. dist[i,j] = ||A[i,:]-B[j,:]||_2
    """
    A_norm = (A**2).sum(axis=1).reshape(A.shape[0], 1)
    # (A**2).sum(axis=1) it's a 1D array with sum of each row
    # reshape(1, A.shape[0]) it's a 1xN array
    # A.shape[0] is N
    # A_norm => a Nx1 array
    B_norm = (B**2).sum(axis=1).reshape(1, B.shape[0])
    # (A**2).sum(axis=1) it's a 1D array with sum of each row
    # reshape(1, B.shape[0]) it's a 1xN array
    # B.shape[0] is M
    # B_norm => a 1xM array
    dist = np.sqrt(A_norm + B_norm - 2 * A.dot(B.transpose())) # NxM
    # √(||A[i] - B[j]||²) = √(||A[i]||² + ||B[j]||² - 2·(A[i] · B[j]))  
    # A.dot(B.transpose()) is a NxM matrix
    # A_norm + B_norm is a NxM matrix
    # 2 * A.dot(B.transpose()) is a NxM matrix
    # dist is a NxM matrix
    return dist


def knn(k: int, train_data: Array, train_labels: Array, valid_data: Array) -> Array:
    """Uses the supplied training inputs and labels to make
    predictions for validation data using the K-nearest neighbours
    algorithm.

    Note: N_TRAIN is the number of training examples,
          N_VALID is the number of validation examples,
          M is the number of features per example.

    :param k: The number of neighbours to use for classification
    of a validation example.
    :param train_data: N_TRAIN x M array of training data.
    :param train_labels: N_TRAIN x 1 vector of training labels
    corresponding to the examples in train_data (must be binary).
    :param valid_data: N_VALID x M array of data to
    predict classes for validation data.
    :return: N_VALID x 1 vector of predicted labels for
    the validation data.
    """
    dist = l2_distance(valid_data, train_data)
    nearest = np.argsort(dist, axis=1)[:, :k] # N_VALID x k, give index of k nearest neighbors

    train_labels = train_labels.reshape(-1)
    valid_labels = train_labels[nearest]

    # Note this only works for binary labels:
    valid_labels = (np.mean(valid_labels, axis=1) >= 0.5).astype(int)
    valid_labels = valid_labels.reshape(-1, 1)

    return valid_labels


def run_knn(k_vals: list[int]) -> None:
    train_inputs, train_targets = None, None
    valid_inputs, valid_targets = None, None
    test_inputs, test_targets = None, None

    #####################################################################
    # TODO:                                                             #
    # Implement a function that runs kNN for different values of k,     #
    # plots the classification rate on the validation set, and etc.     #
    # as required for Q3.1 (a) and (b).                                 #
    #####################################################################
    valid_accuracies = []
    test_accuracies = []
    for k in k_vals:
        valid_labels = knn(k, train_inputs, train_targets, valid_inputs)
        test_labels = knn(k, train_inputs, train_targets, test_inputs)
        valid_accuracy = np.mean(valid_labels == valid_targets)
        test_accuracy = np.mean(test_labels == test_targets)
        valid_accuracies.append(valid_accuracy)
        test_accuracies.append(test_accuracy)
        print(f"K={k}, Valid Accuracy={valid_accuracy}, Test Accuracy={test_accuracy}")
        

    plt.plot(k_vals, valid_accuracies, 'bo-', linewidth=2, markersize=8)
    plt.plot(k_vals, test_accuracies, 'ro-', linewidth=2, markersize=8)
    plt.legend(['Validation Accuracy', 'Test Accuracy'])
    plt.xlabel('K (Number of Neighbors)')
    plt.ylabel('Classification Accuracy')
    plt.title('k-NN Classification Accuracy vs K')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("knn.png")


if __name__ == "__main__":
    run_knn([1, 3, 5, 7, 9])
